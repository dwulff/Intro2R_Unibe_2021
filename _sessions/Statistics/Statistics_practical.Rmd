---
title: "Statistics"
author: "<table style='table-layout:fixed;width:100%;border:0;padding:0;margin:0'><col width='10%'><col width='10%'>
  <tr style='border:none'>
    <td style='display:block;width:100%;text-align:left;vertical-align:bottom;padding:0;margin:0;border:none' nowrap>
      <font style='font-style:normal'>Introduction to R</font><br>
      <a href='https://therbootcamp.github.io/SmR_2021Apr/'>
        <i class='fas fa-clock' style='font-size:.9em;' ></i>
      </a>
      <a href='https://therbootcamp.github.io'>
        <i class='fas fa-home' style='font-size:.9em;'></i>
      </a>
      <a href='mailto:therbootcamp@gmail.com'>
        <i class='fas fa-envelope' style='font-size: .9em;'></i>
      </a>
      <a href='https://www.linkedin.com/company/basel-r-bootcamp/'>
        <i class='fab fa-linkedin' style='font-size: .9em;'></i>
      </a>
      <a href='https://therbootcamp.github.io'>
        <font style='font-style:normal'>The R Bootcamp</font>
      </a>
    </td>
    <td style='width:100%;vertical-align:bottom;text-align:right;padding:0;margin:0;border:none'>
      <img src='https://raw.githubusercontent.com/therbootcamp/therbootcamp.github.io/master/_sessions/_image/by-sa.png' style='height:15px;width:80px'/>
    </td>
  </tr></table>"
output:
  html_document:
    css: practical.css
    self_contained: no
---

```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(comment = NA, 
                      fig.width = 6, 
                      fig.height = 6,
                      fig.align = 'center',
                      echo = TRUE, 
                      eval = TRUE, 
                      warning = FALSE)

options(digits = 3)

# Load packages
library(tidyverse)

# Load packages
wein <- read_csv("1_Data/wein.csv")

```

<p align="center" width="100%">
  <img src="image/vinho2.png" alt="Trulli" style="width:100%">
  <br>
  <font style="font-size:10px">from <a href="https://www.delinat.com/weinlese-blog/wie-lange-ist-ein-wein-haltbar/">delinat.com</a></font>
</p>


# {.tabset}

## Überblick

At the end of this practical you will be able to ...

1. use categorical variables as predictors in a regression 
2. know how to add an interaction effect and understand why it might be important to standardize your variables

## Aufgaben

### A - Setup

2. Open your `BernRBootcamp` R project. It should already have the folders `1_Data` and `2_Code`. Make sure that the data files listed in the `Datasets` section above are in your `1_Data` folder.

3. Using `library()` load the set of packages for this practical listed in the Functions section above.

```{r, eval = FALSE, echo = TRUE}
## Name
## Date
## Statistics Practical

library(XX)     
library(XX)
```

4. For this practical we will use a dataset called `wein.csv` which you will now import with  `read_csv()`.

```{r, echo = T, eval = T, message = F}
# Lese Daten ein
wein <- read_csv(file = "1_Data/wein.csv")
```

6. Execute the code below to ensure that all `character` variables are converte to factors. This will help the statistical model to interpret categorical variables correctly. 

```{r, echo = TRUE}
# convert character to factor
wein <- wein %>% mutate_if(is.character, factor)
```


### B - Comparing groups: <i>t</i>-test versus regression

1. In this part we will inspect the effect of `Farbe` (color) of the wine, red or white, as a predictor for  `Qualität` (quality). Use the code below to generate two vectors that include quality ratings for white and red wine. 

```{r, echo = TRUE}
# Qualitätsvektoren nach Farbe
weiss <- wein %>% filter(Farbe == 'weiss') %>% pull(Qualität)
rot <- wein %>% filter(Farbe == 'rot') %>% pull(Qualität)
```

2. Use the `t.test()` template below to compare the two vectors with a <i>t</i>-test. You do not have to save the result.

```{r, eval = FALSE, echo = TRUE}
# t-test
t.test(x = XX, y = XX)
```

```{r}
# t-test
t.test(x = weiss, y = rot)
```

3. What does the output tell of the <i>t</i>-tests tell you about the difference between white and red wine in perceived quality? You will find the answer in the second line of the output that starts with `t=..` and in the last line.  

4. White wine got a higher rating with `0.2419` (difference of the two means) points more than red wine, this difference is significant. Now, try to get the same result with a regression. Predict `Qualität` with `Farbe`.

```{r, eval = FALSE, echo = TRUE}
# Regression
wein_lm <- lm(formula = XX ~ XX, 
              data = XX)
```

```{r}
# Regression
wein_lm <- lm(formula = Qualität ~ Farbe, 
              data = wein)
```

5. Print the object and inspect the regression weights. Do you recognize some of these numbers?

6. Exactly! The regression weight for `Farbe` is the mean difference of red and white wines. What does the intercept represent? It represents the value of the category that got assigned 0 by R. As this variable is `character` the default behavior is assigned to the category that comes earlier in the alphabet, i.e., `'rot' < 'weiss'`.   

7. Now use the `summary()` function on your model object and compare the degrees of freedom, <i>t</i>- and p-value with the ones from the <i>t</i>-test above. 

```{r}
# summary
summary(wein_lm)
```

8. The values from the t-test do not exactly match the estimations for the weights in the regression. This stems from the fact that the `t.test()` function allows the variance of the groups (rot and weiss) to be different. In contracts regression always assumes that the variances between groups are the same, we will talk about this more in the robust statistics session. Re-calculate the <i>t</i>-test with the argumente `var.equal = TRUE`.   

```{r, eval = FALSE, echo = TRUE}
# t-test
t.test(x = XX, y = XX, var.equal = XX)
```

```{r}
# t-test
t.test(x = weiss, y = rot, var.equal = TRUE)
```

9. Order has been resumed! All values in teh <i>t</i>-test and the regression should be identical now. 

### C - Gruppenvergleiche: Kodierung

1. Per Default verwendet R die Dummy-Kodierung, in der eine Ausprägung den Wert 0 erhält und eine andere den Wert 1. Eine alternative Kodierung existiert in der Effektkodierung, die stattdessen die Werte -1 und 1 vergibt. Um die Konsequenzen dieser beiden Kodierungen direkt zu vergleichen, erstelle zunächst für jede Kodierung eine neue Variable im Datensatz unter Verwendung des Codes unten. 

```{r, echo = TRUE}
# Kodierungen der Farbe
wein <- wein %>% mutate(Farbe_dummy = ifelse(Farbe == 'rot', 0, 1),
                        Farbe_effekt = ifelse(Farbe == 'rot', -1, 1))
```

2. Rechne nun zwei Regressionen, jeweils eine mit einer der beiden Farbkodierungen als Prädiktor und speichere sie ab als `wein_dummy` und `wein_effekt`.   

```{r, eval = FALSE, echo = TRUE}
# Regression dummy
wein_dummy <- lm(formula = XX ~ XX, 
                 data = XX)

# Regression effekt
wein_effekt <- lm(formula = XX ~ XX, 
                  data = XX)
```

```{r}
# Regression dummy
wein_dummy <- lm(formula = Qualität ~ Farbe_dummy, 
                 data = wein)

# Regression effekt
wein_effekt <- lm(formula = Qualität ~ Farbe_effekt, 
                  data = wein)
```

3. Printe nun die beiden Objekte und vergleiche die Gewichte. Diejenigen der Dummy-Kodierung sollten dir bekannt vorkommen. Wie verhalten sich die Gewichte der Effektkodierung dagegen? Erkennst du den Zusammenhang?

4. Der Effekt der Farbe unter der Effektkodierung entspricht genau der Hälfte des Effekts unter der Dummykodierung und um dies auszugleichen hat sich der Intercept auch um genau den selben Wert verändert, nur in die andere Richtung. Verifiziere die Gewichte mit den einfachen Rechnungen im Code unten. 

```{r, echo = TRUE}
# Dummy-Kodierung
mean(rot) # intercept
mean(weiss) - mean(rot) # gewicht farbe

# EffekKodierung
(mean(rot) + mean(weiss))/2 # intercept
mean(weiss) - (mean(rot) + mean(weiss))/2 # gewicht farbe
```

5. Vergleiche nun die `summary()` der beiden Modelle. Was unterscheidet sich, und was nicht?

```{r}
# Regression dummy
summary(wein_dummy)

# Regression effekt
summary(wein_effekt)
```

6. Die Kodierung hat ausgenommen die Skalierung des Regressionsgewichts und des zugehörigen Standardfehlers keinen Einfluss. <i>t</i>-Wert und Signifikanz sind identisch. Einzig der Intercept ändert sich wesentlich, da er unter der Effektkodierung tatsächlich weiter von Null entfernt ist.

### D - Interaktionen

1. Der erste Abschnitt hat gezeigt, dass weisser Wein gegenüber Rotem bevorzugt wurde. Könnte dies daran liegen, dass nicht für andere Variablen kontrolliert wurde? Oder könnte es sein, dass dieser Unterschied nur unter bestimmten Bedingungen gilt, d.h., dass es Moderatoren für den Effekt der Farbe gibt? Rechne eine Regression die zusätzlich `Alkohol` mit aufnimmt und verknüpfe die Prädiktoren mit `*` sodass auch die Interaktion berücksichtigt wird.   

```{r, eval = FALSE, echo = TRUE}
# Regression mit Interaktion
wein_lm <- lm(formula = XX ~ XX * XX, 
              data = XX)
```

```{r}
# Regression mit Interaktion
wein_lm <- lm(formula = Qualität ~ Farbe * Alkohol, 
              data = wein)
```

2. Printe das Objekt und betrachte die Gewichte. Wie interpretierst du die einzelnen Werte?

3. Die Gewichte lassen sich folgendermassen interpretieren: Unter Berücksichtigung von Alkohol und der Interaktion, werden weisse Weine um `.7` besser bewertet. Unter Berücksichtigung der Farbe und der Interaktion, führt ein Anstieg von einem Volumenprozent zu einer Verbesserung der wahrgenommenen Qualität von `.36`. Unter Berücksichtigung von Farbe und Alkohol, führt die Interaktion, also das Produkt der beiden Prädiktoren zu einer Veränderung von `-.05`. Dies ist so zu interpretieren, dass der Effekt von Alkohol unter Weissweinen um genau diese Grösse kleiner ist. Dies bedeutet im Umkehrschluss dass der Effekt von Farbe unter hoch-alkoholischen Weinen kleiner ausfällt. Verwendet den Code unten um diese Ergebnisse zu visualisieren. Gelb bedeutet Weisswein, lila (dunkel blau, fast schwarz) Rotwein.

```{r, echo =T}
# Visualisierung
ggplot(data = wein, 
       aes(x = Alkohol, y = Qualität, col = Farbe, alpha = .01)) + 
  scale_color_manual(values = viridis::cividis(2)) + 
  geom_jitter(width=2,height=1.5,size=.1) + theme_minimal() + theme(legend.position = 'none') +
  geom_smooth(data = wein %>% filter(Farbe == 'weiss'), method = 'lm') + 
  geom_smooth(data = wein %>% filter(Farbe == 'rot'), method = 'lm')

```

4. Lasse dir nun die `summary()` anzeigen und inspiziere die <i>t</i>-Werte und Signifikanzen. Welche Prädiktoren sind signifikant?

5. Alle drei Prädiktoren sind signifikant. <i>t</i>-Wert und Signifikanz sind am extremsten für `Alkohol`, jedoch ist das Gewicht für `Alkohol` nur halb so gross. Wie ist dies zu erklären?  

6. Genau die Gewichte hängen auch von der Skalierung der Prädiktoren ab. Rechne nun die Regression noch einmal, aber diesmal mit skalierten Prädiktoren. Siehe Code unten.

```{r, eval = FALSE, echo = TRUE}
# Skalierungsfunktion
skaliere = function(x) (x - mean(x))/sd(x)

# Regression mit skalierten Prädiktoren
wein_lm <- lm(formula = XX ~ XX * XX, 
              data = XX %>% mutate_if(is.numeric, skaliere))
```

```{r}
# Skalierungsfunktion
skaliere = function(x) (x - mean(x))/sd(x)

# Regression mit skalierten Prädiktoren
wein_lm <- lm(formula = Qualität ~ Farbe * Alkohol, 
              data = wein %>% mutate_if(is.numeric, skaliere))
```

7. Printe zunächst einmal das Objekt und betrachte die Gewichte. Alle Werte haben sich substantiell verändert. Insbesondere hat nun Alkohol das zweifach höhere Gewicht. Wie sind diese neuen Gewichte zu interpretieren, wenn du bedenkst, dass nach der Skalierung alle Variablen eine Standardabweichung = 1 haben? 

8. Nach Skalierung sind die Gewichte als Veränderungen in Standardabweichungen zu interpretieren. Z.B., eine Veränderung von einer Standardabweichungen in `Alkohol` führt demnach zu einer Veränderung von `.4928` Standardabweichungen in der Qualität. Am meisten hat sich der Intercept verändert. Wie interpretiert ihr diesen unter der Skalierung?     

9. Der Intercept ist der geschätzte Mittelwert des Kriteriums für den Fall in dem alle Prädiktoren Null sind. Ohne Skalierung ist dieser Fall schwer zu interpretieren, da Null nicht vorkommen muss in den Prädiktoren. Unter der Skalierung ändert sich dies aber, denn nun haben alle Prädiktoren, mit Ausnahme des Faktors `Farbe` einen Mittelwert von Null. Das heisst der Intercept spiegelt die Qualität für ein mittleres Level von Alkohol, rote Weine und keine Interaktion in Standardabweichungen wieder. Dies kannst du wiederum in der Visualisierung nachvollziehen. Benutze den Code unten und suche den Punkt auf der lila Linie für Alkohol = 0.    

```{r, echo = T}
# Visualisierung
ggplot(data = wein %>% mutate_if(is.numeric, skaliere), 
       aes(x = Alkohol, y = Qualität, col = Farbe, alpha = .01)) + 
  scale_color_manual(values = viridis::cividis(2))  +
  geom_jitter(width=2,height=1.5,size=.1) + theme_minimal() + theme(legend.position = 'none') +
  geom_smooth(data = wein %>% mutate_if(is.numeric, skaliere) %>% filter(Farbe == 'weiss'), method = 'lm') + 
  geom_smooth(data = wein %>% mutate_if(is.numeric, skaliere) %>% filter(Farbe == 'rot'), method = 'lm')

```

10. Schaue dir nun die `summary()` an. Was hat sich verändert bzgl. <i>t</i>-Werten, Signifikanzen, und Standardfehlern, und R-squared? 

11. Ein wesentlicher Einfluss besteht auf die Variable `Farbe`, welche als einzige nicht mit standardisiert wurde. Vor der Standardisierung von `Alkohol` war Farbe beinahe perfekt mit der Interaktion korreliert, was zu einem extrem aufgeblasenen Standardfehler geführt hat. Die Standardisierung hat diese Korrelation jedoch stark reduziert, so dass der Standardfehler auf das Niveau der anderen Prädiktoren gefallen ist. In der Konklusion lohnt es sich beinahe immer die Prädiktoren (oder auch das Kriterium) zu standardisieren, wenn ein Vergleich der Gewichte und Signifikanzen von Interesse ist. 

## Beispiele

```{r, eval = FALSE, echo = TRUE}
# Regression mit R

library(tidyverse)

# Model:
# Sagt der Hubraum (displ) die pro gallone 
# fahrbaren Meilen voraus?
hwy_mod <- lm(formula = hwy ~ displ,
               data = mpg)

# Ergebnisse 
summary(hwy_mod)
coef(hwy_mod)

# Gefittete Werte
hwy_fit <- fitted(hwy_mod)
hwy_fit

# Residuums 
hwy_resid <- residuals(hwy_mod)
hwy_resid

```


## Datensätze

|Datei | Zeile | Spalte |
|:----|:-----|:------|
|[wein.csv](https://raw.githubusercontent.com/therbootcamp/SmR_2020Mai/master/TheRBootcamp/1_Data/wein.csv) | 6497 | 13 |

#### wein.csv

Der `wein.csv` Datensatz enthält aus den Jahren 2004 bis 2007 des Comissão De Viticultura Da Região Dos Vinhos Verdes, der Offiziellen Zertifizierungsagentur des Vinho Verde in Portugal.

| Name | Beschreibung |
|:-------------|:-------------------------------------|
|Qualität | Qualitätsurteil über den Wein von 1-9 |
|Farbe| Roter oder weisser Wein |
|Gelöste_Säure| Konzentration der im Wein gelösten Säuren |
|Freie_Säure| Konzentration der verflüchtigbaren Säuren |
|Citronensäure| Citronensäurekonzentration im Wein |
|Restzucker| Zuckerkonzentration im Wein|
|Chloride| Chloridkonzentration im Wein|
|Freie_Schwefeldioxide| Konzentration der verflüchtigbaren Schwefeldioxide |
|Gesamt_Schwefeldioxide| Konzentration der Schwefeldioxide insgesamt |
|Dichte|Dichte des Weins|
|pH_Wert|pH-Wert des Weins. Je kleiner, desto saurer. |
|Sulphate| Sulphatkontration im Wein |
|Alkohol| Alkoholkonzentration im Wein in %|

## Funktionen

### Pakete

|Package| Installation|
|:------|:------|
|`tidyverse`|`install.packages("tidyverse")`|

### Funktionen

| Function| Package | Description |
|:---|:------|:---------------------------------------------|
|   `lm`|`stats`| Fitte ein lineares Modell  |
|   `fitted`|`stats`| Extrahiere vorhergesagte Werte|
|   `residuals`|`stats`| Extrahiere Residuen |

## Resourcen

### Books

- [Discovering Statistics with R](https://www.amazon.com/Discovering-Statistics-Using-Andy-Field/dp/1446200469) von Andy Field ist sehr gut
- [YaRrr! The Pirate's Guide to R](https://bookdown.org/ndphillips/YaRrr/) hat hilfreiche und unterhaltsame Kapitel zu Statistik mit R.
